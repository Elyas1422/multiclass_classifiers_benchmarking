{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary and Discussion\n",
    "\n",
    "We evaluated the performance of various machine learning models, including Support Vector Machine (SVM), Logistic Regression, Neural Network (NN), Decision Tree (DT), Random Forest, and two Active Learning approaches (least confident and entropy) using Random Forest.\n",
    "\n",
    "We have choose the random forest for active learning as it's showed the best results.\n",
    "\n",
    "| Model               | Accuracy | F1-Score (Macro) | Precision (Macro) | Recall (Macro) | F1-Score (Weighted) | Precision (Weighted) | Recall (Weighted) |\n",
    "|---------------------|----------|-------------------|---------------------|-----------------|----------------------|-----------------------|-------------------|\n",
    "| SVM                 | 92%      | 88%               | 88%                 | 89%             | 91%                  | 92%                   | 92%               |\n",
    "| Logistic Regression | 84%      | 76%               | 77%                 | 75%             | 84%                  | 84%                   | 84%               |\n",
    "| NN                  | 90%      | 82%               | 83%                 | 82%             | 90%                  | 90%                   | 90%               |\n",
    "| DT                  | 92%      | 88%               | 87%                 | 89%             | 92%                  | 92%                   | 92%               |\n",
    "| Random Forest       | 94%      | 88%               | 93%                 | 86%             | 94%                  | 94%                   | 94%               |\n",
    "| Active Learning RF(Entropy)  | 94%      | 88%               | 92%                 | 86%             | 93%                  | 94%                   | 94%               |\n",
    "\n",
    "**Overall Observation:**\n",
    "\n",
    "\n",
    "- **Random Forest** emerged as the top-performing model, showcasing a strong ability to generalize well to unseen data.\n",
    "- **Active Learning RF(Entropy)** Showed similar results as the Random Forest\n",
    "- **SVM and Decision Tree** also delivered robust performances, indicating their suitability for the classification task.\n",
    "- **Neural Network** demonstrated competitive results but with a marginally lower accuracy.\n",
    "- **Logistic Regression** exhibited slightly lower performance, suggesting limitations in capturing complex relationships within the data.\n",
    "\n",
    "In conclusion, the choice of the best model depends on specific requirements such as interpretability, computational efficiency, and the importance of accurately capturing patterns in the data. The Random Forest model, with its high accuracy and balanced metrics, stands out as a promising choice for this classification task.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
