{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay, classification_report,f1_score\n",
    "import re\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from statistics import mean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "\n",
    "### modAL \n",
    "from modal.models import ActiveLearner, Committee \n",
    "from modal.density import information_density\n",
    "from modal.disagreement import max_disagreement_sampling, vote_entropy_sampling\n",
    "from modal.uncertainty import uncertainty_sampling, entropy_sampling, margin_sampling, classifier_entropy, classifier_margin, classifier_uncertainty\n",
    "\n",
    "### sklearn\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import LabelEncoder, normalize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "### Suppresses Warning\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "MY_PC = '.'\n",
    "MY_DRIVE = '/content/drive/MyDrive/KFUPM/ICS485 Machine Learning/machine-learning'\n",
    "\n",
    "\n",
    "working_on = MY_PC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(working_on + \"/preprocessed_data/train_data.csv\")\n",
    "val_data = pd.read_csv(working_on + \"/preprocessed_data/val_data.csv\")\n",
    "test_data = pd.read_csv(working_on + \"/preprocessed_data/test_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some info of the labeled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>X10</th>\n",
       "      <th>X13_ FC11</th>\n",
       "      <th>X13_ FC13</th>\n",
       "      <th>X13_ FC14</th>\n",
       "      <th>X14_ CA23</th>\n",
       "      <th>X14_ CA50</th>\n",
       "      <th>X14_ CA59</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.520449</td>\n",
       "      <td>-1.428585</td>\n",
       "      <td>1.530877</td>\n",
       "      <td>-1.162058</td>\n",
       "      <td>-0.836349</td>\n",
       "      <td>-0.535183</td>\n",
       "      <td>-1.042610</td>\n",
       "      <td>-2.433676</td>\n",
       "      <td>-0.612921</td>\n",
       "      <td>-0.707368</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Mercedes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.019717</td>\n",
       "      <td>-0.578489</td>\n",
       "      <td>1.649464</td>\n",
       "      <td>-0.522458</td>\n",
       "      <td>-0.204228</td>\n",
       "      <td>-0.694313</td>\n",
       "      <td>1.210780</td>\n",
       "      <td>-1.719345</td>\n",
       "      <td>-2.155114</td>\n",
       "      <td>-0.453929</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>BMW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.149807</td>\n",
       "      <td>0.019739</td>\n",
       "      <td>0.226418</td>\n",
       "      <td>-0.658669</td>\n",
       "      <td>-0.263490</td>\n",
       "      <td>-0.870256</td>\n",
       "      <td>1.034734</td>\n",
       "      <td>0.185537</td>\n",
       "      <td>-0.753121</td>\n",
       "      <td>-0.819252</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Honda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.708274</td>\n",
       "      <td>-0.415010</td>\n",
       "      <td>1.530877</td>\n",
       "      <td>-0.984392</td>\n",
       "      <td>-0.540042</td>\n",
       "      <td>-1.025183</td>\n",
       "      <td>1.316407</td>\n",
       "      <td>-1.147880</td>\n",
       "      <td>-1.944815</td>\n",
       "      <td>-0.890957</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Honda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.034608</td>\n",
       "      <td>-0.534895</td>\n",
       "      <td>1.175115</td>\n",
       "      <td>0.667908</td>\n",
       "      <td>1.711888</td>\n",
       "      <td>-0.910489</td>\n",
       "      <td>1.210780</td>\n",
       "      <td>-1.100258</td>\n",
       "      <td>-1.734516</td>\n",
       "      <td>-0.234488</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Mercedes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         X1        X2        X3        X4        X5        X6        X7  \\\n",
       "0 -1.520449 -1.428585  1.530877 -1.162058 -0.836349 -0.535183 -1.042610   \n",
       "1  0.019717 -0.578489  1.649464 -0.522458 -0.204228 -0.694313  1.210780   \n",
       "2 -1.149807  0.019739  0.226418 -0.658669 -0.263490 -0.870256  1.034734   \n",
       "3 -1.708274 -0.415010  1.530877 -0.984392 -0.540042 -1.025183  1.316407   \n",
       "4 -1.034608 -0.534895  1.175115  0.667908  1.711888 -0.910489  1.210780   \n",
       "\n",
       "         X8        X9       X10  X13_ FC11  X13_ FC13  X13_ FC14  X14_ CA23  \\\n",
       "0 -2.433676 -0.612921 -0.707368        0.0        0.0        1.0        0.0   \n",
       "1 -1.719345 -2.155114 -0.453929        0.0        1.0        0.0        0.0   \n",
       "2  0.185537 -0.753121 -0.819252        0.0        0.0        1.0        0.0   \n",
       "3 -1.147880 -1.944815 -0.890957        0.0        0.0        1.0        0.0   \n",
       "4 -1.100258 -1.734516 -0.234488        0.0        0.0        1.0        1.0   \n",
       "\n",
       "   X14_ CA50  X14_ CA59         Y  \n",
       "0        0.0        0.0  Mercedes  \n",
       "1        0.0        0.0       BMW  \n",
       "2        0.0        0.0     Honda  \n",
       "3        0.0        0.0     Honda  \n",
       "4        0.0        0.0  Mercedes  "
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column</th>\n",
       "      <th>Non-Null Count</th>\n",
       "      <th>Dtype</th>\n",
       "      <th>Unique Values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Y</th>\n",
       "      <td>Y</td>\n",
       "      <td>6714</td>\n",
       "      <td>object</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X1</th>\n",
       "      <td>X1</td>\n",
       "      <td>6714</td>\n",
       "      <td>float64</td>\n",
       "      <td>1393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X2</th>\n",
       "      <td>X2</td>\n",
       "      <td>6714</td>\n",
       "      <td>float64</td>\n",
       "      <td>2763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X3</th>\n",
       "      <td>X3</td>\n",
       "      <td>6714</td>\n",
       "      <td>float64</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X4</th>\n",
       "      <td>X4</td>\n",
       "      <td>6714</td>\n",
       "      <td>float64</td>\n",
       "      <td>657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X5</th>\n",
       "      <td>X5</td>\n",
       "      <td>6714</td>\n",
       "      <td>float64</td>\n",
       "      <td>306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X6</th>\n",
       "      <td>X6</td>\n",
       "      <td>6714</td>\n",
       "      <td>float64</td>\n",
       "      <td>3077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X7</th>\n",
       "      <td>X7</td>\n",
       "      <td>6714</td>\n",
       "      <td>float64</td>\n",
       "      <td>167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X8</th>\n",
       "      <td>X8</td>\n",
       "      <td>6714</td>\n",
       "      <td>float64</td>\n",
       "      <td>131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X9</th>\n",
       "      <td>X9</td>\n",
       "      <td>6714</td>\n",
       "      <td>float64</td>\n",
       "      <td>243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X10</th>\n",
       "      <td>X10</td>\n",
       "      <td>6714</td>\n",
       "      <td>float64</td>\n",
       "      <td>3008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X13_ FC11</th>\n",
       "      <td>X13_ FC11</td>\n",
       "      <td>6714</td>\n",
       "      <td>float64</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X13_ FC13</th>\n",
       "      <td>X13_ FC13</td>\n",
       "      <td>6714</td>\n",
       "      <td>float64</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X13_ FC14</th>\n",
       "      <td>X13_ FC14</td>\n",
       "      <td>6714</td>\n",
       "      <td>float64</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X14_ CA59</th>\n",
       "      <td>X14_ CA59</td>\n",
       "      <td>6714</td>\n",
       "      <td>float64</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X14_ CA23</th>\n",
       "      <td>X14_ CA23</td>\n",
       "      <td>6714</td>\n",
       "      <td>float64</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X14_ CA50</th>\n",
       "      <td>X14_ CA50</td>\n",
       "      <td>6714</td>\n",
       "      <td>float64</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Column  Non-Null Count    Dtype  Unique Values\n",
       "Y                  Y            6714   object              6\n",
       "X1                X1            6714  float64           1393\n",
       "X2                X2            6714  float64           2763\n",
       "X3                X3            6714  float64             48\n",
       "X4                X4            6714  float64            657\n",
       "X5                X5            6714  float64            306\n",
       "X6                X6            6714  float64           3077\n",
       "X7                X7            6714  float64            167\n",
       "X8                X8            6714  float64            131\n",
       "X9                X9            6714  float64            243\n",
       "X10              X10            6714  float64           3008\n",
       "X13_ FC11  X13_ FC11            6714  float64              2\n",
       "X13_ FC13  X13_ FC13            6714  float64              2\n",
       "X13_ FC14  X13_ FC14            6714  float64              2\n",
       "X14_ CA59  X14_ CA59            6714  float64              2\n",
       "X14_ CA23  X14_ CA23            6714  float64              2\n",
       "X14_ CA50  X14_ CA50            6714  float64              2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def display_dataframe_summary(dataframe, sort_by='Column'):\n",
    "\n",
    "    summary = pd.DataFrame({\n",
    "        'Column': dataframe.columns,\n",
    "        'Non-Null Count': dataframe.notnull().sum(),\n",
    "        'Dtype': dataframe.dtypes,\n",
    "        'Unique Values': dataframe.nunique()\n",
    "    })\n",
    "\n",
    "    # Extracting numerical part from column names for sorting\n",
    "    summary['Sort Key'] = summary['Column'].apply(lambda x: int(re.search(r'\\d+', x).group()) if re.search(r'\\d+', x) else 0)\n",
    "\n",
    "    # Sorting the summary DataFrame\n",
    "    if sort_by == 'Column':\n",
    "        summary = summary.sort_values(by='Sort Key', ascending=True)\n",
    "    else:\n",
    "        summary = summary.sort_values(by=sort_by, ascending=True)\n",
    "\n",
    "    summary = summary.drop('Sort Key', axis=1)  # Remove the auxiliary sort key column\n",
    "\n",
    "    # Display the summary\n",
    "    display(summary)\n",
    "\n",
    "    # Plotting missing data\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.heatmap(dataframe.isnull(), yticklabels=False, cbar=False, cmap='viridis')\n",
    "    plt.title('Missing Data in DataFrame')\n",
    "    plt.show()\n",
    "\n",
    "# Call the function with your DataFrame\n",
    "display_dataframe_summary(train_data, sort_by='Column')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classes is: ['Mercedes' 'BMW' 'Honda' 'Toyota' 'GMC' 'Ford']\n",
      "Number of classes: 6\n",
      "Index(['Y'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "classes = train_data[\"Y\"].unique()\n",
    "number_of_classes = train_data[\"Y\"].nunique()\n",
    "categorical_cols = train_data.select_dtypes(include=['object', 'category']).columns\n",
    "\n",
    "print(f\"The classes is: {classes}\")\n",
    "print(f\"Number of classes: {number_of_classes}\")\n",
    "print(categorical_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = train_data.drop('Y', axis=1).to_numpy()\n",
    "# y_train = pd.get_dummies(train_data['Y']).to_numpy()\n",
    "\n",
    "# X_val = val_data.drop('Y', axis=1).to_numpy()\n",
    "# y_val = pd.get_dummies(val_data['Y']).to_numpy()\n",
    "\n",
    "# X_test = test_data.drop('Y', axis=1).to_numpy()\n",
    "# y_test = pd.get_dummies(test_data['Y']).to_numpy()\n",
    "\n",
    "\n",
    "X_train = train_data.drop('Y', axis=1).to_numpy()\n",
    "y_train = train_data['Y']\n",
    "y_train = LabelEncoder().fit_transform(y_train)\n",
    "\n",
    "\n",
    "X_val = val_data.drop('Y', axis=1).to_numpy()\n",
    "y_val = pd.get_dummies(val_data['Y']).to_numpy()\n",
    "# y_train = LabelEncoder().fit_transform(y_train)\n",
    "\n",
    "X_test = test_data.drop('Y', axis=1).to_numpy()\n",
    "y_test = test_data['Y']\n",
    "y_train = LabelEncoder().fit_transform(y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training set contains one instance from each of 10 labels\n",
    "X_training, y_training = [], []\n",
    "for i in range(6):\n",
    "    \n",
    "    # return index of first element in list with label i\n",
    "    unique_label_idx = list(y_train).index(i)\n",
    "    \n",
    "    # get the feature array corresponding to this element\n",
    "    xx = X_train[unique_label_idx]\n",
    "    \n",
    "    # add instance to training data\n",
    "    X_training.append(xx)\n",
    "    y_training.append(i)\n",
    "    \n",
    "    # remove instance from original data\n",
    "    X_train, y_train  = np.delete(X_train, unique_label_idx, axis=0), np.delete(y_train, unique_label_idx, axis=0)\n",
    "\n",
    "    \n",
    "# split remaining data into pool and test subsets\n",
    "X_pool, X_test, y_pool, y_test = train_test_split(X_train,y_train,test_size=0.5,random_state=777)\n",
    "\n",
    "# convert lists to numpy arrays\n",
    "X_training = np.asarray(X_training)\n",
    "y_training = np.asarray(y_training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_query(classifier, X):\n",
    "    \n",
    "    n_samples = len(X)\n",
    "    query_idx = np.random.choice(range(n_samples))\n",
    "    return query_idx, X[query_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_sample(learner, X, y):\n",
    "\n",
    "    \n",
    "    # call the query strategy defined in the learner to obtain a new sample\n",
    "    query_idx, query_sample = learner.query(X)\n",
    "    \n",
    "    # modify indexing to interpret as collection of one element with 26 features\n",
    "    query_sample_reshaped = query_sample.reshape(1,-1)\n",
    "   \n",
    "    # obtain the query label\n",
    "    query_label = y[query_idx]\n",
    "\n",
    "    # modify indexing to interpret as 1D array of one element\n",
    "    query_label_reshaped = query_label.reshape(1,)\n",
    "    \n",
    "    return query_sample_reshaped, query_label_reshaped, query_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_active_learner(learner, X_pool, y_pool, X_test, y_test, num_queries):\n",
    "   \n",
    "    history = [] # score history\n",
    "    \n",
    "    # score model before active learning starts\n",
    "    history.append(learner.score(X_test,y_test))\n",
    "\n",
    "    # perform active learning\n",
    "    for idx in range(num_queries):\n",
    "\n",
    "        # get sample\n",
    "        X_sample, y_sample, query_idx = get_next_sample(learner, X_pool, y_pool)\n",
    "\n",
    "        # use new sample to update the model\n",
    "        learner.teach(X_sample, y_sample)\n",
    "\n",
    "        # score against test data\n",
    "        current_score = learner.score(X_test,y_test)\n",
    "\n",
    "        # save score\n",
    "        history.append(current_score)\n",
    "        \n",
    "        # remove labeled instance from pool\n",
    "        X_pool = np.delete(X_pool, query_idx, axis=0)\n",
    "        y_pool = np.delete(y_pool, query_idx)\n",
    "        \n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into a pool (unlabeled) and an initial labeled set\n",
    "X_initial, X_pool, y_initial, y_pool = train_test_split(\n",
    "    X_train, y_train, train_size=100, stratify=y_train\n",
    ")\n",
    "\n",
    "# copy data for use with this section\n",
    "X_pool_rand_lr = copy.deepcopy(X_pool)\n",
    "y_pool_rand_lr = copy.deepcopy(y_pool)\n",
    "\n",
    "\n",
    "\n",
    "# define learner, including training data as starting point\n",
    "learner = ActiveLearner(\n",
    "    estimator=LogisticRegression(),\n",
    "    query_strategy=random_query,\n",
    "    X_training=X_initial, \n",
    "    y_training=y_initial\n",
    ")\n",
    "\n",
    "\n",
    "# run active learner and obtain score history\n",
    "history_rand_lr = run_active_learner(learner, X_pool_rand_lr, y_pool_rand_lr, X_test, y_test, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7426952892069171,\n",
       " 0.7423971377459749,\n",
       " 0.751937984496124,\n",
       " 0.753726893261777,\n",
       " 0.753726893261777,\n",
       " 0.7552176505664878,\n",
       " 0.7558139534883721,\n",
       " 0.7552176505664878,\n",
       " 0.7540250447227191,\n",
       " 0.7510435301132976,\n",
       " 0.7510435301132976,\n",
       " 0.7492546213476446,\n",
       " 0.7507453786523554,\n",
       " 0.7510435301132976,\n",
       " 0.7528324388789505,\n",
       " 0.7546213476446034,\n",
       " 0.753726893261777,\n",
       " 0.7540250447227191,\n",
       " 0.7525342874180083,\n",
       " 0.7522361359570662,\n",
       " 0.7513416815742398,\n",
       " 0.7531305903398927,\n",
       " 0.7596899224806202,\n",
       " 0.7596899224806202,\n",
       " 0.7590936195587359,\n",
       " 0.7590936195587359,\n",
       " 0.7590936195587359,\n",
       " 0.7587954680977936,\n",
       " 0.7587954680977936,\n",
       " 0.7656529516994633,\n",
       " 0.7653548002385212,\n",
       " 0.7641621943947525,\n",
       " 0.7644603458556947,\n",
       " 0.7635658914728682,\n",
       " 0.7668455575432319,\n",
       " 0.7668455575432319,\n",
       " 0.7665474060822898,\n",
       " 0.7665474060822898,\n",
       " 0.7671437090041742,\n",
       " 0.7671437090041742,\n",
       " 0.7671437090041742,\n",
       " 0.7665474060822898,\n",
       " 0.7674418604651163,\n",
       " 0.7674418604651163,\n",
       " 0.7674418604651163,\n",
       " 0.7683363148479427,\n",
       " 0.7686344663088849,\n",
       " 0.768932617769827,\n",
       " 0.7695289206917114,\n",
       " 0.7701252236135957,\n",
       " 0.77072152653548,\n",
       " 0.7701252236135957,\n",
       " 0.7701252236135957,\n",
       " 0.7695289206917114,\n",
       " 0.7692307692307693,\n",
       " 0.7686344663088849,\n",
       " 0.7737030411449016,\n",
       " 0.7751937984496124,\n",
       " 0.7754919499105546,\n",
       " 0.7740011926058438,\n",
       " 0.7731067382230173,\n",
       " 0.7701252236135957,\n",
       " 0.7701252236135957,\n",
       " 0.7710196779964222,\n",
       " 0.7716159809183065,\n",
       " 0.7701252236135957,\n",
       " 0.768932617769827,\n",
       " 0.7698270721526536,\n",
       " 0.7695289206917114,\n",
       " 0.7695289206917114,\n",
       " 0.7692307692307693,\n",
       " 0.7692307692307693,\n",
       " 0.7698270721526536,\n",
       " 0.7698270721526536,\n",
       " 0.7686344663088849,\n",
       " 0.7692307692307693,\n",
       " 0.7659511031604055,\n",
       " 0.7659511031604055,\n",
       " 0.7668455575432319,\n",
       " 0.7701252236135957,\n",
       " 0.7674418604651163,\n",
       " 0.7674418604651163,\n",
       " 0.7659511031604055,\n",
       " 0.7662492546213476,\n",
       " 0.7692307692307693,\n",
       " 0.7695289206917114,\n",
       " 0.7701252236135957,\n",
       " 0.7710196779964222,\n",
       " 0.7716159809183065,\n",
       " 0.77072152653548,\n",
       " 0.7728085867620751,\n",
       " 0.7719141323792487,\n",
       " 0.7719141323792487,\n",
       " 0.7716159809183065,\n",
       " 0.7719141323792487,\n",
       " 0.7719141323792487,\n",
       " 0.7716159809183065,\n",
       " 0.7713178294573644,\n",
       " 0.7713178294573644,\n",
       " 0.7716159809183065,\n",
       " 0.7713178294573644]"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_rand_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final accuracy of Logistic Regression with random sampling: \t0.771\n"
     ]
    }
   ],
   "source": [
    "# final accuracy\n",
    "print('Final accuracy of Logistic Regression with random sampling: \\t{:.3f}'.format(history_rand_lr[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Split the data into a pool (unlabeled) and an initial labeled set\n",
    "X_initial, X_pool, y_initial, y_pool = train_test_split(\n",
    "    X_train, y_train, train_size=100, stratify=y_train\n",
    ")\n",
    "\n",
    "model = xgb.XGBClassifier(n_estimators=1000, max_depth=7, learning_rate=0.1, random_state=777)\n",
    "\n",
    "# Train the initial model on the labeled samples\n",
    "model.fit(X_initial, y_initial)\n",
    "\n",
    "# Number of samples to query in each iteration\n",
    "query_size = 10\n",
    "\n",
    "# Calculate initial f1 scores\n",
    "training_f1_initial = f1_score(y_initial, model.predict(X_initial), average='macro')\n",
    "validation_f1_initial = f1_score(y_val, model.predict(X_val), average='macro')  # Assuming y_val and X_val are your validation data\n",
    "\n",
    "print(\"Original model performance: \")\n",
    "print(f\"Training f1 score: {training_f1_initial:.2f}\")\n",
    "print(f\"Validation f1 score: {validation_f1_initial:.2f}\")\n",
    "print(\"-\" * 100)\n",
    "\n",
    "# Number of iterations\n",
    "# num_iterations = (len(X_pool) - len(X_initial)) // query_size\n",
    "num_iterations = 5\n",
    "\n",
    "\n",
    "for i in range(num_iterations):\n",
    "    # Calculate predicted probabilities for each class\n",
    "    probas = model.predict_proba(X_pool)\n",
    "\n",
    "    # Calculate the least confident score for each sample\n",
    "    least_confident_scores = 1 - np.max(probas, axis=1)\n",
    "\n",
    "    # Select the top 'query_size' samples with the lowest confidence\n",
    "    query_indices = np.argsort(least_confident_scores)[:query_size]\n",
    "\n",
    "    # Label the selected samples and remove them from the pool\n",
    "    X_query = X_pool[query_indices]\n",
    "    y_query = model.predict(X_query)\n",
    "\n",
    "    X_pool = np.delete(X_pool, query_indices, axis=0)\n",
    "    y_pool = np.delete(y_pool, query_indices)\n",
    "\n",
    "    # Add the newly labeled samples to the initial set\n",
    "    X_initial = np.vstack([X_initial, X_query])\n",
    "    y_initial = np.concatenate([y_initial, y_query])\n",
    "\n",
    "    # Retrain the model on the updated labeled set\n",
    "    model.fit(X_initial, y_initial)\n",
    "\n",
    "    # Calculate f1 scores\n",
    "    training_f1 = f1_score(y_initial, model.predict(X_initial), average='macro')\n",
    "    validation_f1 = f1_score(y_val, model.predict(X_val), average='macro')\n",
    "\n",
    "    print(f\"Iteration {i+1} performance:\")\n",
    "    print(f\"Training f1 score: {training_f1:.2f}\")\n",
    "    print(f\"Validation f1 score: {validation_f1:.2f}\")\n",
    "    print(\"-\" * 100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Showing model performance on testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model,X_test,y_test):\n",
    "    \n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    test_accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Final accuracy on the test set: {test_accuracy:.4f}\")\n",
    "\n",
    "    cm = confusion_matrix(np.argmax(y_test, axis=1), np.argmax(y_pred, axis=1))\n",
    "    cm_display = ConfusionMatrixDisplay(confusion_matrix = cm, display_labels = classes)\n",
    "    \n",
    "    print(\"Confusion Matrix:\")\n",
    "    cm_display.plot()\n",
    "    plt.show()\n",
    "    \n",
    "    report = classification_report(y_test, y_pred, target_names=classes)\n",
    "    print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Active Learning RF(Entropy) Model Performance on Testing Set:')\n",
    "evaluate_model(model,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
