{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1701208141270,
     "user": {
      "displayName": "Ammar Almajed",
      "userId": "02912955514166358537"
     },
     "user_tz": -180
    },
    "id": "oF1vkucYWaXz"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display\n",
    "import re\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import sklearn.metrics\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RZExDGcxYI30"
   },
   "source": [
    "# Reading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1701208141271,
     "user": {
      "displayName": "Ammar Almajed",
      "userId": "02912955514166358537"
     },
     "user_tz": -180
    },
    "id": "hE7yvYT5W6QA"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Dataset-vf.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1701208141271,
     "user": {
      "displayName": "Ammar Almajed",
      "userId": "02912955514166358537"
     },
     "user_tz": -180
    },
    "id": "bhY7BEb9XRw_",
    "outputId": "6d6bede8-b61e-4a4a-ce0b-5210ddb4f343"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X5</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X6</th>\n",
       "      <th>X1</th>\n",
       "      <th>X10</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>X11</th>\n",
       "      <th>X12</th>\n",
       "      <th>X15</th>\n",
       "      <th>X13</th>\n",
       "      <th>X14</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>43</td>\n",
       "      <td>59.0</td>\n",
       "      <td>11</td>\n",
       "      <td>120</td>\n",
       "      <td>150</td>\n",
       "      <td>2709</td>\n",
       "      <td>2114</td>\n",
       "      <td>228</td>\n",
       "      <td>217</td>\n",
       "      <td>120</td>\n",
       "      <td>0.66</td>\n",
       "      <td>269</td>\n",
       "      <td>R1</td>\n",
       "      <td>FC11</td>\n",
       "      <td>CA49</td>\n",
       "      <td>BMW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>693</td>\n",
       "      <td>2802</td>\n",
       "      <td>162</td>\n",
       "      <td>224</td>\n",
       "      <td>225</td>\n",
       "      <td>136</td>\n",
       "      <td>0.35</td>\n",
       "      <td>195</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FC11</td>\n",
       "      <td>CA50</td>\n",
       "      <td>BMW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1260</td>\n",
       "      <td>2325</td>\n",
       "      <td>162</td>\n",
       "      <td>215</td>\n",
       "      <td>213</td>\n",
       "      <td>133</td>\n",
       "      <td>0.89</td>\n",
       "      <td>750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FC14</td>\n",
       "      <td>CA26</td>\n",
       "      <td>Mercedes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "      <td>112.0</td>\n",
       "      <td>8</td>\n",
       "      <td>272</td>\n",
       "      <td>3649</td>\n",
       "      <td>2837</td>\n",
       "      <td>6221</td>\n",
       "      <td>235</td>\n",
       "      <td>231</td>\n",
       "      <td>128</td>\n",
       "      <td>0.27</td>\n",
       "      <td>-155</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FC11</td>\n",
       "      <td>CA32</td>\n",
       "      <td>Ford</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>59.0</td>\n",
       "      <td>7</td>\n",
       "      <td>134</td>\n",
       "      <td>900</td>\n",
       "      <td>2509</td>\n",
       "      <td>5184</td>\n",
       "      <td>226</td>\n",
       "      <td>226</td>\n",
       "      <td>134</td>\n",
       "      <td>0.93</td>\n",
       "      <td>88</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FC11</td>\n",
       "      <td>CA38</td>\n",
       "      <td>BMW</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   X5     X2  X3   X4    X6    X1   X10   X7   X8   X9   X11  X12  X15    X13  \\\n",
       "0  43   59.0  11  120   150  2709  2114  228  217  120  0.66  269   R1   FC11   \n",
       "1   0   54.0   7    0   693  2802   162  224  225  136  0.35  195  NaN   FC11   \n",
       "2   0   28.0  12    0  1260  2325   162  215  213  133  0.89  750  NaN   FC14   \n",
       "3  16  112.0   8  272  3649  2837  6221  235  231  128  0.27 -155  NaN   FC11   \n",
       "4  10   59.0   7  134   900  2509  5184  226  226  134  0.93   88  NaN   FC11   \n",
       "\n",
       "     X14         Y  \n",
       "0   CA49       BMW  \n",
       "1   CA50       BMW  \n",
       "2   CA26  Mercedes  \n",
       "3   CA32      Ford  \n",
       "4   CA38       BMW  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1701208141833,
     "user": {
      "displayName": "Ammar Almajed",
      "userId": "02912955514166358537"
     },
     "user_tz": -180
    },
    "id": "BLFUCv8hTcdM",
    "outputId": "4d20e29b-0068-426a-ce38-ab2ccab8c76c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column</th>\n",
       "      <th>Non-Null Count</th>\n",
       "      <th>Dtype</th>\n",
       "      <th>Unique Values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Y</th>\n",
       "      <td>Y</td>\n",
       "      <td>6124</td>\n",
       "      <td>object</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X1</th>\n",
       "      <td>X1</td>\n",
       "      <td>6124</td>\n",
       "      <td>int64</td>\n",
       "      <td>1395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X2</th>\n",
       "      <td>X2</td>\n",
       "      <td>5520</td>\n",
       "      <td>float64</td>\n",
       "      <td>360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X3</th>\n",
       "      <td>X3</td>\n",
       "      <td>6124</td>\n",
       "      <td>int64</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X4</th>\n",
       "      <td>X4</td>\n",
       "      <td>6124</td>\n",
       "      <td>int64</td>\n",
       "      <td>257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X5</th>\n",
       "      <td>X5</td>\n",
       "      <td>6124</td>\n",
       "      <td>int64</td>\n",
       "      <td>324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X6</th>\n",
       "      <td>X6</td>\n",
       "      <td>6124</td>\n",
       "      <td>int64</td>\n",
       "      <td>2037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X7</th>\n",
       "      <td>X7</td>\n",
       "      <td>6124</td>\n",
       "      <td>int64</td>\n",
       "      <td>169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X8</th>\n",
       "      <td>X8</td>\n",
       "      <td>6124</td>\n",
       "      <td>int64</td>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X9</th>\n",
       "      <td>X9</td>\n",
       "      <td>6124</td>\n",
       "      <td>int64</td>\n",
       "      <td>243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X10</th>\n",
       "      <td>X10</td>\n",
       "      <td>6124</td>\n",
       "      <td>int64</td>\n",
       "      <td>1878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X11</th>\n",
       "      <td>X11</td>\n",
       "      <td>6124</td>\n",
       "      <td>float64</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X12</th>\n",
       "      <td>X12</td>\n",
       "      <td>6124</td>\n",
       "      <td>int64</td>\n",
       "      <td>1894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X13</th>\n",
       "      <td>X13</td>\n",
       "      <td>6124</td>\n",
       "      <td>object</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X14</th>\n",
       "      <td>X14</td>\n",
       "      <td>6124</td>\n",
       "      <td>object</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X15</th>\n",
       "      <td>X15</td>\n",
       "      <td>601</td>\n",
       "      <td>object</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Column  Non-Null Count    Dtype  Unique Values\n",
       "Y        Y            6124   object              6\n",
       "X1      X1            6124    int64           1395\n",
       "X2      X2            5520  float64            360\n",
       "X3      X3            6124    int64             50\n",
       "X4      X4            6124    int64            257\n",
       "X5      X5            6124    int64            324\n",
       "X6      X6            6124    int64           2037\n",
       "X7      X7            6124    int64            169\n",
       "X8      X8            6124    int64            137\n",
       "X9      X9            6124    int64            243\n",
       "X10    X10            6124    int64           1878\n",
       "X11    X11            6124  float64            101\n",
       "X12    X12            6124    int64           1894\n",
       "X13    X13            6124   object              4\n",
       "X14    X14            6124   object             32\n",
       "X15    X15             601   object              4"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "\n",
    "\n",
    "def display_dataframe_summary(dataframe, sort_by='Column'):\n",
    "\n",
    "    summary = pd.DataFrame({\n",
    "        'Column': dataframe.columns,\n",
    "        'Non-Null Count': dataframe.notnull().sum(),\n",
    "        'Dtype': dataframe.dtypes,\n",
    "        'Unique Values': dataframe.nunique()\n",
    "    })\n",
    "\n",
    "    # Extracting numerical part from column names for sorting\n",
    "    summary['Sort Key'] = summary['Column'].apply(lambda x: int(re.search(r'\\d+', x).group()) if re.search(r'\\d+', x) else 0)\n",
    "\n",
    "    # Sorting the summary DataFrame\n",
    "    if sort_by == 'Column':\n",
    "        summary = summary.sort_values(by='Sort Key', ascending=True)\n",
    "    else:\n",
    "        summary = summary.sort_values(by=sort_by, ascending=True)\n",
    "\n",
    "    summary = summary.drop('Sort Key', axis=1)  # Remove the auxiliary sort key column\n",
    "\n",
    "    # Display the summary\n",
    "    display(summary)\n",
    "\n",
    "    # Plotting missing data\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.heatmap(dataframe.isnull(), yticklabels=False, cbar=False, cmap='viridis')\n",
    "    plt.title('Missing Data in DataFrame')\n",
    "    plt.show()\n",
    "\n",
    "# Call the function with your DataFrame\n",
    "display_dataframe_summary(df, sort_by='Column')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 412,
     "status": "ok",
     "timestamp": 1701208144021,
     "user": {
      "displayName": "Ammar Almajed",
      "userId": "02912955514166358537"
     },
     "user_tz": -180
    },
    "id": "_x6WsNDnXjyH",
    "outputId": "757f8d29-02e4-430d-afb3-e4ce273f0e87"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classes is: ['BMW' 'Mercedes' 'Ford' 'Toyota' 'Honda' 'GMC']\n",
      "Number of classes: 6\n",
      "Index(['X15', 'X13', 'X14', 'Y'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "classes = df[\"Y\"].unique()\n",
    "number_of_classes = df[\"Y\"].nunique()\n",
    "categorical_cols = df.select_dtypes(include=['object', 'category']).columns\n",
    "\n",
    "print(f\"The classes is: {classes}\")\n",
    "print(f\"Number of classes: {number_of_classes}\")\n",
    "print(categorical_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3_HZSQUKuvul"
   },
   "source": [
    "# Preprocessing the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MoZoJ9hUSlTF"
   },
   "source": [
    "### Handling numerical missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1701208145055,
     "user": {
      "displayName": "Ammar Almajed",
      "userId": "02912955514166358537"
     },
     "user_tz": -180
    },
    "id": "35nocmQw5nX6"
   },
   "outputs": [],
   "source": [
    "df['X2'] = df['X2'].fillna(value=df['X2'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fYMq3P7eSRk3"
   },
   "source": [
    "### Semi-Supervised Learning Imputation (to fill categorical missing values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sZNQ1KkLSaWE"
   },
   "source": [
    "**MCAR:** is the highest level of randomness and occurs where\n",
    "missingness of attribute values is independent of the values\n",
    "\n",
    "**MAR:** occurs when the probability of a case having\n",
    "a missing value may depend on the known values, but not on the value of the\n",
    "missing data itself\n",
    "\n",
    "**NMAR:** occurs when the probability of a case having a missing value for an attribute could depend on the\n",
    "value of that attribute.\n",
    "\n",
    "\n",
    "Case and attribute removal with missing data should be applied only if\n",
    "missing data are MCAR, as not MCAR missing data have non-random elements,\n",
    "which can make the results biased."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1701208146464,
     "user": {
      "displayName": "Ammar Almajed",
      "userId": "02912955514166358537"
     },
     "user_tz": -180
    },
    "id": "KQ8z0brgSRH9",
    "outputId": "572976bb-8580-4eec-d677-d1641d3b243c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of labeled data: 601, and number of features: 16\n",
      "number of unlabeled data: 5523, and number of features: 16\n"
     ]
    }
   ],
   "source": [
    "mask = pd.isna(df[\"X15\"])\n",
    "labeled = df[~mask]  # Rows where X15 is not NaN\n",
    "unlabeled = df[mask]  # Rows where X15 is NaN\n",
    "\n",
    "print(f\"number of labeled data: {len(labeled)}, and number of features: {len(labeled.columns)}\")\n",
    "print(f\"number of unlabeled data: {len(unlabeled)}, and number of features: {len(unlabeled.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "executionInfo": {
     "elapsed": 499,
     "status": "error",
     "timestamp": 1701208413543,
     "user": {
      "displayName": "Ammar Almajed",
      "userId": "02912955514166358537"
     },
     "user_tz": -180
    },
    "id": "Ap-NXdtzdjxU",
    "outputId": "3751a90e-9bfb-462d-801c-fd43fe59538d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of labeled data: 601, and number of features: 13\n",
      "number of unlabeled data: 5523, and number of features: 13\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Removing other catagorecal values\n",
    "\"\"\"\n",
    "\n",
    "labeled = labeled.drop(columns = [\"Y\", \"X13\", \"X14\"])\n",
    "unlabeled = unlabeled.drop(columns = [\"Y\", \"X13\", \"X14\"])\n",
    "\n",
    "print(f\"number of labeled data: {len(labeled)}, and number of features: {len(labeled.columns)}\")\n",
    "print(f\"number of unlabeled data: {len(unlabeled)}, and number of features: {len(unlabeled.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 67289,
     "status": "ok",
     "timestamp": 1701208481163,
     "user": {
      "displayName": "Ammar Almajed",
      "userId": "02912955514166358537"
     },
     "user_tz": -180
    },
    "id": "pbJREu3neXYK",
    "outputId": "363eff97-2553-4e9b-d861-2d46c0520ebe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R2' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3']\n",
      "['R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3']\n",
      "['R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3']\n",
      "['R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3']\n",
      "['R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3']\n",
      "['R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3']\n",
      "['R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3']\n",
      "['R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3']\n",
      "['R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3'\n",
      " 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3' 'R3']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "\n",
    "batch_size = 516\n",
    "\n",
    "# Assuming 'unlabeled' is a DataFrame with your unlabeled data\n",
    "n_unlabeled = len(unlabeled)\n",
    "\n",
    "# Initial training set\n",
    "X_train = labeled.drop(\"X15\", axis=1)\n",
    "y_train = labeled[\"X15\"]\n",
    "\n",
    "# Loop through unlabeled data in batches\n",
    "for start_index in range(0, n_unlabeled, batch_size):\n",
    "    end_index = min(start_index + batch_size, n_unlabeled)\n",
    "\n",
    "    # Creating the test set for the current batch\n",
    "    X_test = unlabeled.iloc[start_index:end_index].drop(\"X15\", axis=1)\n",
    "    y_test = unlabeled.iloc[start_index:end_index][\"X15\"]\n",
    "\n",
    "    # Here, you would typically use X_test and y_test\n",
    "    # For example, use a model to make predictions and label the data,\n",
    "    # then update labeled and unlabeled datasets accordingly.\n",
    "    # ...\n",
    "\n",
    "    mlp = MLPClassifier(hidden_layer_sizes=(128, 64, 32, 16, 8),\n",
    "                    activation='relu',  # default is 'relu'\n",
    "                    solver='adam',      # default solver is 'adam'\n",
    "                    max_iter=1000,       # default max_iter is 200\n",
    "                    random_state=42)    # for reproducibility\n",
    "\n",
    "    mlp.fit(X_train, y_train)\n",
    "    predictions = mlp.predict(X_test)\n",
    "    print(predictions)\n",
    "\n",
    "\n",
    "    # Assuming you update 'labeled' with the new labels,\n",
    "    # you should also update your training set.\n",
    "    X_train = labeled.drop(\"X15\", axis=1)\n",
    "    y_train = labeled[\"X15\"]\n",
    "\n",
    "    # Optionally, update 'unlabeled' to remove the processed batch\n",
    "    # ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 680,
     "status": "ok",
     "timestamp": 1701208341706,
     "user": {
      "displayName": "Ammar Almajed",
      "userId": "02912955514166358537"
     },
     "user_tz": -180
    },
    "id": "oNAaYBNZ6Mc2",
    "outputId": "adcbe4d9-6a78-433e-f180-e6ca173b8eff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'R': 1, 'R1': 181, 'R2': 190, 'R3': 229}\n"
     ]
    }
   ],
   "source": [
    "unique, counts = np.unique(labeled[\"X15\"], return_counts=True)\n",
    "label_counts = dict(zip(unique, counts))\n",
    "\n",
    "print(label_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1701208174013,
     "user": {
      "displayName": "Ammar Almajed",
      "userId": "02912955514166358537"
     },
     "user_tz": -180
    },
    "id": "_rjw10N2elKM",
    "outputId": "40c08d0d-6266-4b9c-a4bc-e1e5b46b95c7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(      X5          X2  X3   X4    X6    X1   X10   X7   X8   X9   X11  X12\n",
       " 5728  92  210.000000  20  297  1048  2863  1766  201  254  182  0.46  779\n",
       " 5729   0   32.000000   6    0   797  2142  1577  219  226  144  0.03 -354\n",
       " 5730  80  128.000000  32  150  1632  2268    67  252  200   48  0.96   64\n",
       " 5731  70  111.000000   8  558  5840  3218  1589  234  231  129  0.07  462\n",
       " 5732   0  347.000000  17    0  1326  2135  1381  186  211  162  0.35 -154\n",
       " ...   ..         ...  ..  ...   ...   ...   ...  ...  ...  ...   ...  ...\n",
       " 6119  14  151.293659  18   67   918  2712  1922  201  254  183  0.00 -877\n",
       " 6120   1   67.000000   6  170   824  3101  1657  227  228  135  0.50  437\n",
       " 6121  -3  139.000000  13   30  3127  3050  5770  240  235  123  0.74   53\n",
       " 6122  12  106.000000  24   30   582  2080   108  252  202   64  0.88  -79\n",
       " 6123  36  108.000000  10  212  2912  3011  6632  237  229  122  0.67 -299\n",
       " \n",
       " [363 rows x 12 columns],\n",
       " 5728    NaN\n",
       " 5729    NaN\n",
       " 5730    NaN\n",
       " 5731    NaN\n",
       " 5732    NaN\n",
       "        ... \n",
       " 6119    NaN\n",
       " 6120    NaN\n",
       " 6121    NaN\n",
       " 6122    NaN\n",
       " 6123    NaN\n",
       " Name: X15, Length: 363, dtype: object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KsS10GhVYj8H"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "executionInfo": {
     "elapsed": 440,
     "status": "ok",
     "timestamp": 1701160709362,
     "user": {
      "displayName": "Ammar Almajed",
      "userId": "02912955514166358537"
     },
     "user_tz": -180
    },
    "id": "H505sun4vuYI",
    "outputId": "57655130-fbc1-49af-f738-7cbac249b0fa"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X5</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X6</th>\n",
       "      <th>X1</th>\n",
       "      <th>X10</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>X11</th>\n",
       "      <th>X12</th>\n",
       "      <th>X15</th>\n",
       "      <th>X13</th>\n",
       "      <th>X14</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>43</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>11</td>\n",
       "      <td>120</td>\n",
       "      <td>150</td>\n",
       "      <td>2709</td>\n",
       "      <td>2114</td>\n",
       "      <td>228</td>\n",
       "      <td>217</td>\n",
       "      <td>120</td>\n",
       "      <td>0.66</td>\n",
       "      <td>269</td>\n",
       "      <td>R1</td>\n",
       "      <td>FC11</td>\n",
       "      <td>CA49</td>\n",
       "      <td>BMW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>693</td>\n",
       "      <td>2802</td>\n",
       "      <td>162</td>\n",
       "      <td>224</td>\n",
       "      <td>225</td>\n",
       "      <td>136</td>\n",
       "      <td>0.35</td>\n",
       "      <td>195</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FC11</td>\n",
       "      <td>CA50</td>\n",
       "      <td>BMW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1260</td>\n",
       "      <td>2325</td>\n",
       "      <td>162</td>\n",
       "      <td>215</td>\n",
       "      <td>213</td>\n",
       "      <td>133</td>\n",
       "      <td>0.89</td>\n",
       "      <td>750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FC14</td>\n",
       "      <td>CA26</td>\n",
       "      <td>Mercedes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "      <td>112.000000</td>\n",
       "      <td>8</td>\n",
       "      <td>272</td>\n",
       "      <td>3649</td>\n",
       "      <td>2837</td>\n",
       "      <td>6221</td>\n",
       "      <td>235</td>\n",
       "      <td>231</td>\n",
       "      <td>128</td>\n",
       "      <td>0.27</td>\n",
       "      <td>-155</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FC11</td>\n",
       "      <td>CA32</td>\n",
       "      <td>Ford</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>7</td>\n",
       "      <td>134</td>\n",
       "      <td>900</td>\n",
       "      <td>2509</td>\n",
       "      <td>5184</td>\n",
       "      <td>226</td>\n",
       "      <td>226</td>\n",
       "      <td>134</td>\n",
       "      <td>0.93</td>\n",
       "      <td>88</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FC11</td>\n",
       "      <td>CA38</td>\n",
       "      <td>BMW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6119</th>\n",
       "      <td>14</td>\n",
       "      <td>151.293659</td>\n",
       "      <td>18</td>\n",
       "      <td>67</td>\n",
       "      <td>918</td>\n",
       "      <td>2712</td>\n",
       "      <td>1922</td>\n",
       "      <td>201</td>\n",
       "      <td>254</td>\n",
       "      <td>183</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-877</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FC13</td>\n",
       "      <td>CA24</td>\n",
       "      <td>Toyota</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6120</th>\n",
       "      <td>1</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>170</td>\n",
       "      <td>824</td>\n",
       "      <td>3101</td>\n",
       "      <td>1657</td>\n",
       "      <td>227</td>\n",
       "      <td>228</td>\n",
       "      <td>135</td>\n",
       "      <td>0.50</td>\n",
       "      <td>437</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FC11</td>\n",
       "      <td>CA43</td>\n",
       "      <td>Toyota</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6121</th>\n",
       "      <td>-3</td>\n",
       "      <td>139.000000</td>\n",
       "      <td>13</td>\n",
       "      <td>30</td>\n",
       "      <td>3127</td>\n",
       "      <td>3050</td>\n",
       "      <td>5770</td>\n",
       "      <td>240</td>\n",
       "      <td>235</td>\n",
       "      <td>123</td>\n",
       "      <td>0.74</td>\n",
       "      <td>53</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FC11</td>\n",
       "      <td>CA40</td>\n",
       "      <td>Toyota</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6122</th>\n",
       "      <td>12</td>\n",
       "      <td>106.000000</td>\n",
       "      <td>24</td>\n",
       "      <td>30</td>\n",
       "      <td>582</td>\n",
       "      <td>2080</td>\n",
       "      <td>108</td>\n",
       "      <td>252</td>\n",
       "      <td>202</td>\n",
       "      <td>64</td>\n",
       "      <td>0.88</td>\n",
       "      <td>-79</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FC14</td>\n",
       "      <td>CA23</td>\n",
       "      <td>Mercedes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6123</th>\n",
       "      <td>36</td>\n",
       "      <td>108.000000</td>\n",
       "      <td>10</td>\n",
       "      <td>212</td>\n",
       "      <td>2912</td>\n",
       "      <td>3011</td>\n",
       "      <td>6632</td>\n",
       "      <td>237</td>\n",
       "      <td>229</td>\n",
       "      <td>122</td>\n",
       "      <td>0.67</td>\n",
       "      <td>-299</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FC11</td>\n",
       "      <td>CA49</td>\n",
       "      <td>Toyota</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6124 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      X5          X2  X3   X4    X6    X1   X10   X7   X8   X9   X11  X12  \\\n",
       "0     43   59.000000  11  120   150  2709  2114  228  217  120  0.66  269   \n",
       "1      0   54.000000   7    0   693  2802   162  224  225  136  0.35  195   \n",
       "2      0   28.000000  12    0  1260  2325   162  215  213  133  0.89  750   \n",
       "3     16  112.000000   8  272  3649  2837  6221  235  231  128  0.27 -155   \n",
       "4     10   59.000000   7  134   900  2509  5184  226  226  134  0.93   88   \n",
       "...   ..         ...  ..  ...   ...   ...   ...  ...  ...  ...   ...  ...   \n",
       "6119  14  151.293659  18   67   918  2712  1922  201  254  183  0.00 -877   \n",
       "6120   1   67.000000   6  170   824  3101  1657  227  228  135  0.50  437   \n",
       "6121  -3  139.000000  13   30  3127  3050  5770  240  235  123  0.74   53   \n",
       "6122  12  106.000000  24   30   582  2080   108  252  202   64  0.88  -79   \n",
       "6123  36  108.000000  10  212  2912  3011  6632  237  229  122  0.67 -299   \n",
       "\n",
       "      X15    X13    X14         Y  \n",
       "0      R1   FC11   CA49       BMW  \n",
       "1     NaN   FC11   CA50       BMW  \n",
       "2     NaN   FC14   CA26  Mercedes  \n",
       "3     NaN   FC11   CA32      Ford  \n",
       "4     NaN   FC11   CA38       BMW  \n",
       "...   ...    ...    ...       ...  \n",
       "6119  NaN   FC13   CA24    Toyota  \n",
       "6120  NaN   FC11   CA43    Toyota  \n",
       "6121  NaN   FC11   CA40    Toyota  \n",
       "6122  NaN   FC14   CA23  Mercedes  \n",
       "6123  NaN   FC11   CA49    Toyota  \n",
       "\n",
       "[6124 rows x 16 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1701160709363,
     "user": {
      "displayName": "Ammar Almajed",
      "userId": "02912955514166358537"
     },
     "user_tz": -180
    },
    "id": "rv00Aixcv7R8",
    "outputId": "d45eb7eb-a2a9-4dd5-9574-23143dd9ba3c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6124 entries, 0 to 6123\n",
      "Data columns (total 16 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   X5      6124 non-null   int64  \n",
      " 1   X2      6124 non-null   float64\n",
      " 2   X3      6124 non-null   int64  \n",
      " 3   X4      6124 non-null   int64  \n",
      " 4   X6      6124 non-null   int64  \n",
      " 5   X1      6124 non-null   int64  \n",
      " 6   X10     6124 non-null   int64  \n",
      " 7   X7      6124 non-null   int64  \n",
      " 8   X8      6124 non-null   int64  \n",
      " 9   X9      6124 non-null   int64  \n",
      " 10  X11     6124 non-null   float64\n",
      " 11  X12     6124 non-null   int64  \n",
      " 12  X15     601 non-null    object \n",
      " 13  X13     6124 non-null   object \n",
      " 14  X14     6124 non-null   object \n",
      " 15  Y       6124 non-null   object \n",
      "dtypes: float64(2), int64(10), object(4)\n",
      "memory usage: 765.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "TO_lynk31MA2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['BMW' 'BMW' 'Mercedes' ... 'Toyota' 'Mercedes' 'Toyota']\n"
     ]
    }
   ],
   "source": [
    "# features = df.drop(\"Y\", axis=1)\n",
    "features = df.drop(categorical_cols, axis=1)\n",
    "labels = df[\"Y\"]\n",
    "# labels = pd.get_dummies(labels, \"Y\")\n",
    "\n",
    "# Converting to numpy array\n",
    "features = features.to_numpy()\n",
    "labels = labels.to_numpy()\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7gjYj8gmv_93"
   },
   "source": [
    "### Spliting data into train, val, and test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1701160709363,
     "user": {
      "displayName": "Ammar Almajed",
      "userId": "02912955514166358537"
     },
     "user_tz": -180
    },
    "id": "ev7FTyX7v9NE",
    "outputId": "3bbc8a80-cb0d-428e-99e8-2d16261fc83e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X train shape:  (5205, 12)\n",
      "y train shape:  (5205,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.15, random_state=42)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.5, random_state=42)\n",
    "\n",
    "# X_train, y_train = X_train.T, y_train.T\n",
    "# X_val, y_val = X_val.T, y_val.T\n",
    "# X_test, y_test = X_test.T, y_test.T\n",
    "\n",
    "\n",
    "# Normal scaling\n",
    "mean = np.mean(X_train, axis=0, keepdims=True)\n",
    "std = np.std(X_train, axis=0, keepdims=True)\n",
    "\n",
    "X_train = (X_train - mean) / std\n",
    "X_val = (X_val - mean) / std\n",
    "X_test = (X_test - mean) / std\n",
    "\n",
    "\n",
    "print(\"X train shape: \", X_train.shape)\n",
    "print(\"y train shape: \", y_train.shape)\n",
    "# print(f\"Number of classes: {labels.shape[1]}\")\n",
    "# print ('Number of features per sample: ' + str(X_train.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3NK-DFBJ1qHp"
   },
   "source": [
    "# Building SVM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for SVM: {'C': 100, 'degree': 2, 'kernel': 'rbf'}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=100, degree=2, random_state=777)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=100, degree=2, random_state=777)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(C=100, degree=2, random_state=777)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import make_scorer, f1_score\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "    'kernel': ['linear', 'poly', 'rbf'],\n",
    "    'degree': [2, 3, 4, 5]\n",
    "}\n",
    "\n",
    "# Create an SVM model\n",
    "svm_model = SVC(random_state=777)\n",
    "\n",
    "# Use F1-macro as the scoring metric\n",
    "f1_macro_scorer = make_scorer(f1_score, average='macro')\n",
    "\n",
    "# Create a GridSearchCV object with F1-macro scoring\n",
    "grid_search = GridSearchCV(estimator=svm_model, param_grid=param_grid, scoring=f1_macro_scorer, cv=5)\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best hyperparameters and model\n",
    "best_params = grid_search.best_params_\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(f'Best params for SVM: {best_params}')\n",
    "\n",
    "# You can access the best model directly\n",
    "# best_model.fit(X_train, y_train)\n",
    "\n",
    "# Or you can use the best parameters to create a new model\n",
    "final_model = SVC(**best_params, random_state=777)\n",
    "X_train = np.vstack([X_train, X_val])\n",
    "y_train = np.concatenate((y_train, y_val), axis = 0)\n",
    "final_model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Elyas Almubarak\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Elyas Almubarak\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Elyas Almubarak\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Elyas Almubarak\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Elyas Almubarak\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Elyas Almubarak\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Elyas Almubarak\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Elyas Almubarak\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Elyas Almubarak\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Elyas Almubarak\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Elyas Almubarak\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Elyas Almubarak\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Elyas Almubarak\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Elyas Almubarak\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Elyas Almubarak\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Elyas Almubarak\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Elyas Almubarak\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Elyas Almubarak\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Elyas Almubarak\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Elyas Almubarak\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Elyas Almubarak\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Elyas Almubarak\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Elyas Almubarak\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Elyas Almubarak\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Elyas Almubarak\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Elyas Almubarak\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for Logistic Regression: {'C': 10, 'penalty': 'l1', 'solver': 'saga'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Elyas Almubarak\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=10, penalty=&#x27;l1&#x27;, random_state=777, solver=&#x27;saga&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=10, penalty=&#x27;l1&#x27;, random_state=777, solver=&#x27;saga&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(C=10, penalty='l1', random_state=777, solver='saga')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import make_scorer, f1_score\n",
    "\n",
    "# Define the parameter grid for logistic regression\n",
    "param_grid = {\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'solver': ['liblinear', 'saga']\n",
    "}\n",
    "\n",
    "# Create a logistic regression model\n",
    "logreg_model = LogisticRegression(random_state=777)\n",
    "\n",
    "# Use F1-macro as the scoring metric\n",
    "f1_macro_scorer = make_scorer(f1_score, average='macro')\n",
    "\n",
    "# Create a GridSearchCV object with F1-macro scoring\n",
    "grid_search = GridSearchCV(estimator=logreg_model, param_grid=param_grid, scoring=f1_macro_scorer, cv=5)\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best hyperparameters and model\n",
    "best_params = grid_search.best_params_\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(f'Best params for Logistic Regression: {best_params}')\n",
    "\n",
    "# You can access the best model directly\n",
    "# best_model.fit(X_train, y_train)\n",
    "\n",
    "# Or you can use the best parameters to create a new model\n",
    "final_model = LogisticRegression(**best_params, random_state=777)\n",
    "final_model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sWgyiqVm2zgk"
   },
   "source": [
    "# Fine Tuning the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YL2Q9CVa26pm"
   },
   "source": [
    "# Showing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.81\n",
      "Precision: 0.73\n",
      "Recall: 0.66\n",
      "F1-score: 0.68\n",
      "Confusion Matrix:\n",
      "[[100   2   0   5   0   5]\n",
      " [  2   1   0   0   0   2]\n",
      " [  0   0  10   0   0  14]\n",
      " [ 10   0   0  66  24   0]\n",
      " [  0   0   0  14 119   0]\n",
      " [  7   0   2   0   0  76]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y_pred = final_model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='macro')\n",
    "recall = recall_score(y_test, y_pred, average='macro')\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1-score: {f1:.2f}\")\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 300,
     "status": "ok",
     "timestamp": 1701161927483,
     "user": {
      "displayName": "Ammar Almajed",
      "userId": "02912955514166358537"
     },
     "user_tz": -180
    },
    "id": "2KDX8DRW27WI",
    "outputId": "93ae90a3-0fb9-4e18-db61-40c37705647e"
   },
   "outputs": [],
   "source": [
    "# # Print out results.\n",
    "for hs,lr in sorted(results):\n",
    "    train_accuracy, val_accuracy = results[(hs,lr)]\n",
    "    print(f'hs {hs} lr {lr} train accuracy: {train_accuracy:.2f} val accuracy: {val_accuracy:.2f}')\n",
    "\n",
    "print('best validation accuracy achieved during cross-validation: %.2f' % best_val)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2NGP9ChK2TOG"
   },
   "source": [
    "# Testing Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1701161929575,
     "user": {
      "displayName": "Ammar Almajed",
      "userId": "02912955514166358537"
     },
     "user_tz": -180
    },
    "id": "OMYk5P5I12IJ",
    "outputId": "c5560827-ae31-46b7-c56a-25300571878b"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Print accuracy\n",
    "predictions = predict(best_parameters, X_test)\n",
    "print(accuracy_score(np.argmax(y_test, axis = 0), predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1701161929880,
     "user": {
      "displayName": "Ammar Almajed",
      "userId": "02912955514166358537"
     },
     "user_tz": -180
    },
    "id": "Hk6xnw3ME3tS",
    "outputId": "8c64f87b-9c6d-4741-9833-c3371471b1ca"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "y_true = np.argmax(y_test, axis = 0)\n",
    "y_pred = predictions\n",
    "\n",
    "\n",
    "report = classification_report(y_true, y_pred, target_names=classes)\n",
    "\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FZPJattzHBWV"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn\n",
    "import sklearn.linear_model\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 449
    },
    "executionInfo": {
     "elapsed": 465,
     "status": "ok",
     "timestamp": 1701161932518,
     "user": {
      "displayName": "Ammar Almajed",
      "userId": "02912955514166358537"
     },
     "user_tz": -180
    },
    "id": "Xp7PhG4WE6JH",
    "outputId": "9853961d-ac72-43e6-b992-1469a4f6ccfc"
   },
   "outputs": [],
   "source": [
    "confusion_matrix = sklearn.metrics.confusion_matrix(np.argmax(y_test, axis = 0), predictions)\n",
    "cm_display = sklearn.metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix, display_labels = classes)\n",
    "\n",
    "cm_display.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pgG58QwIJxJy"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPhGMxfRMNarZFNSQOt0Q1B",
   "gpuType": "T4",
   "mount_file_id": "1iD8gRDfwwFvIpUgif1LlnhThfxYKSvCz",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
